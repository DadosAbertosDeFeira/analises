{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuvem de palavras das propostas dos candidatos a prefeito de Feira de Santana\n",
    "\n",
    "Os candidatos a prefeito das cidades precisam submeter uma proposta\n",
    "de governo. Os links para as propostas estão disponíveis no portal\n",
    "[DivulgaCandContas](https://divulgacandcontas.tse.jus.br/) do TSE.\n",
    "\n",
    "Através de uma iniciativa colaborativa, coletamos os links e extraímos\n",
    "o texto das propostas. Veja mais sobre isso no [Dados de planos de governo de candidatos às prefeituras dos municípios em 2020](https://dadosabertos.social/t/dados-de-planos-de-governo-de-candidatos-as-prefeituras-dos-municipios-em-2020/645/1).\n",
    "\n",
    "Para rodar essa análise você deve:\n",
    "* Baixar o arquivo [propostas.7z](https://github.com/augusto-herrmann/eleicoes-2020-planos-de-governo/blob/main/dados/propostas.7z)\n",
    "* Extraí-lo na pasta `analysis` ou modificar a variável `proposals_directory` com o caminho completo para a pasta\n",
    "\n",
    "Padrão de pastas esperado: `propostas > sigla do estado > cidades`\n",
    "\n",
    "---\n",
    "\n",
    "Nessa análise vamos visualizar uma nuvem de palavras das propostas a\n",
    "candidatos de toda Bahia e de Feira de Santana.\n",
    "\n",
    "Com isso queremos responder as perguntas:\n",
    "\n",
    "1. Quais são as palavras de destaque entre os candidatos a prefeito de Feira?\n",
    "2. Quais são as palavras de destaque entre todos os candidatos a prefeito de Feira juntos?\n",
    "3. Quais são as palavras de destaque entre todos os candidatos a prefeito da Bahia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "target_state = \"ba\"  # sigla do estado em minúsculo\n",
    "target_city = \"feira-de-santana\"  # nome da cidade separado por hífens\n",
    "proposals_directory = \"propostas/\"\n",
    "proposals_and_cities = {}\n",
    "\n",
    "# estrutura: estado > cidade > proposta-<candidato>.txt\n",
    "for folder, _, files in os.walk(proposals_directory):\n",
    "    if files:\n",
    "        index_city = folder.rfind(\"/\")\n",
    "        city = folder[index_city+1:]\n",
    "        index_state = folder[:index_city].rfind(\"/\")\n",
    "        state = folder[index_state+1:index_city]\n",
    "        proposals_and_cities[f\"{state}/{city}\"] = files\n",
    "proposals_and_cities[f\"{target_state}/{target_city}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propostas por candidato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.nlp import remove_portuguese_stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "\n",
    "\n",
    "custom_pipeline = [preprocessing.remove_digits,\n",
    "                   preprocessing.remove_diacritics,\n",
    "                   preprocessing.remove_whitespace]\n",
    "\n",
    "candidates_and_proposals = {}\n",
    "for file_name in proposals_and_cities[f\"{target_state}/{target_city}\"]:\n",
    "    candidate_name = file_name[12:]\n",
    "    candidate_name = candidate_name.replace(\".txt\", \"\")\n",
    "    candidate_name = candidate_name.replace(\"-\", \" \")\n",
    "    candidate_name = candidate_name.title()\n",
    "    print(candidate_name)\n",
    "    content = open(f\"{directory}/{file_name}\").read()\n",
    "    custom_stop_words = [\"feira\", \"santana\", \"municipio\", \"municipal\", \"município\", \"municipais\", \"cidade\"]\n",
    "    cleaned_text = remove_portuguese_stopwords(content, custom_stop_words)\n",
    "    cleaned_text = pd.Series(cleaned_text)\n",
    "    cleaned_text = hero.clean(cleaned_text, custom_pipeline)\n",
    "    candidates_and_proposals[candidate_name] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate, proposal in candidates_and_proposals.items():\n",
    "    print(f\"------------------------ {candidate}\")\n",
    "    text = \" \".join(proposal)\n",
    "    wordcloud = WordCloud(background_color=\"white\", width=2000, height=800, colormap=\"PuOr\", collocations=False).generate(text)\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    fig.savefig(f\"nuvem-de-palavras-das-propostas-de-{candidate.replace(' ', '-').lower()}.png\", dpi=fig.dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não foi possível visualizar as propostas da candidata Professora Dayane Pimentel porque\n",
    "o arquivo é composto de imagens, ao invés de texto. Tentamos contato com a candidata\n",
    "para corrigir o arquivo, não apenas por conta da análise mas também porque não é acessível\n",
    "para pessoas com deficiência, porém fomos ignorados.\n",
    "\n",
    "\n",
    "## O que acontece se juntarmos todos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proposals = []\n",
    "for _, proposal in candidates_and_proposals.items():\n",
    "    all_proposals.extend(proposal)\n",
    "\n",
    "imagem = cv2.imread(\"images/caixa-dagua-do-tomba.jpg\")\n",
    "gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "ret,mask = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "text = \" \".join(all_proposals)\n",
    "wordcloud = WordCloud(background_color=\"white\", mask=mask, collocations=False, colormap=\"RdYlGn\").generate(text)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "fig.savefig(f\"nuvem-de-palavras-dos-candidatos-a-prefeito-de-feira.png\", dpi=fig.dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E na Bahia?\n",
    "\n",
    "O que será que as propostas de todos os candidatos a prefeito dizem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.nlp import remove_portuguese_stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "\n",
    "\n",
    "custom_pipeline = [preprocessing.remove_digits,\n",
    "                   preprocessing.remove_diacritics,\n",
    "                   preprocessing.remove_whitespace]\n",
    "\n",
    "all_proposals = []\n",
    "for city, proposals in proposals_and_cities.items():\n",
    "    for proposal in proposals:\n",
    "        content = open(f\"{city}/{proposal}\").read()\n",
    "        custom_stop_words = [\"municipio\", \"municipal\", \"município\"]\n",
    "        cleaned_text = remove_portuguese_stopwords(content, custom_stop_words)\n",
    "        cleaned_text = pd.Series(cleaned_text)\n",
    "        cleaned_text = hero.clean(cleaned_text, custom_pipeline)\n",
    "        all_proposals.extend(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(all_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\", width=2000, height=800, colormap=\"RdBu\", collocations=False).generate(text)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "fig.savefig(f\"nuvem-de-palavras-dos-candidatos-prefeito-bahia.png\", dpi=fig.dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com as nuvens de palavras, saúde e educação são os temas que mais se destacam entre os planos de governo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
