{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bitdafsaanalisesb94857b5318c463e9159f3e68c6000f6",
      "display_name": "Python 3.8.2 64-bit ('dafsa-analises')"
    },
    "colab": {
      "name": "semelhanca_leis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "source": [
        "# Semelhança de documentos\n",
        "\n",
        "A função desse notebook é criar representações para o texto dos documentos,\n",
        "exibir textos semelhantes e com isso avaliar as representações.\n",
        "Os textos semelhantes são um teste para a representação do texto:\n",
        "se os textos mostrados não são semelhantes, então a representação não é boa;\n",
        "se são semelhantes, então a representação um pouco melhor.\n",
        "\n",
        "## Dados\n",
        "\n",
        "Embora a proposta deste notebook um template genérico para comparação de textos,\n",
        "neste notebook utilizamos o dataset das leis municipais, disponível\n",
        "[aqui](https://www.kaggle.com/anapaulagomes/leis-do-municpio-de-feira-de-santana/).\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw0cBhm80T-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9rDGqZO0cbK",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "f084561d-b993-4e0d-f456-a01a0f3cb626"
      },
      "source": [
        "laws_file = 'leis.json'\n",
        "\n",
        "# Descomente pra usar no Google Colab\n",
        "# from google.colab import files\n",
        "# import os.path\n",
        "\n",
        "\n",
        "# if (not os.path.isfile(laws_file)):\n",
        "#     uploaded = files.upload()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "SvTVbdbn0T-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "84f7d034-d28f-4582-9842-a1925c045c26"
      },
      "source": [
        "laws = pd.read_json(laws_file)\n",
        "laws.drop(['documento'], inplace=True, axis=1)\n",
        "laws.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHdRkZoU0T_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "731a47c1-d4e0-4f50-83d4-fbd8e1e33ca6"
      },
      "source": [
        "laws.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bY1XZSe0T_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "104ae31c-0044-4273-b2f9-00838ffec295"
      },
      "source": [
        "# Exemplo de texto de lei\n",
        "print(laws.loc[len(laws)-1, 'texto'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3JpPMrw0T_Z",
        "colab_type": "text"
      },
      "source": [
        "## Comparando documentos: representação e calculo de similaridade\n",
        "\n",
        "Para comparar quão parecido são dois documentos,\n",
        "primeiro temos que transformar estes documentos \n",
        "para uma representação que o computador consiga calcular alguma coisa a respeito.\n",
        "Existem alguns métodos para isto.\n",
        "Neste notebook temos 3: TF, TF-IDF e vetores de palavras.\n",
        "Para calcular a similaridade, também existem alguns métodos diferentes.\n",
        "Utilizamos similaridade do cosseno.\n",
        "\n",
        "### Term Frequency (TF)\n",
        "\n",
        "A primeira representação construída é bastante ingênua:\n",
        "apenas conta a quantidade de vezes que cada palavra apareceu em cada texto\n",
        "e atribui um vetor pra esse texto.\n",
        "Cada posição do vetor é uma palavra\n",
        "e cada valor representa quantas vezes essa palavra apareceu no dado texto.\n",
        "Todos os textos, portanto, são representados por uma matriz\n",
        "de dimensões _m_ x _n_, onde _m_ é o número de textos \n",
        "e _n_ é o número de palavras únicas (tamanho do vocabulário)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEh4OLr-0T_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scripts.parsers import clean_text\n",
        "laws['texto_limpo'] = laws['texto'].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SPaMnra0T_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bdabe518-a835-4d1e-f5cd-17744618cf27"
      },
      "source": [
        "# Generates document matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "vectorizer = CountVectorizer()\n",
        "tf_representation = vectorizer.fit_transform(laws['texto_limpo'])\n",
        "tf_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Com a matriz de documentos ~literalmente~ em mãos,\n",
        "vamos calcular a similaridade entre dois textos.\n",
        "A similaridade é calculada pela similaridade do cosseno (ver algebra linear).\n",
        "Existem outras medidas pra calcular similaridade / distância.\n",
        "Uma discussão sobre isso [aqui](https://cmry.github.io/notes/euclidean-v-cosine)."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZImYpcZ0T_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "cos_sim_matrix = cosine_similarity(tf_representation, dense_output=True)\n",
        "# sorts ascending, per row, \n",
        "# the indexes of the documents according to their cossine similarity\n",
        "cos_sim_argsort = np.argsort(cos_sim_matrix) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "D1Qr2msI0T_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bfd3a37-6ef9-488e-d315-2316f2325f9c"
      },
      "source": [
        "most_similar_indexes_tf = cos_sim_argsort[:,-2] # -1 is the same text\n",
        "tf_similarities = [cos_sim_matrix[i, ind] for i, ind in enumerate(most_similar_indexes_tf)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Px1gHxey0T_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd18530f-37b5-498d-b2ef-05f7936a3a49"
      },
      "source": [
        "def print_laws(original_law_index, compared_law_index: int):\n",
        "    print(f'- - - LEI: {original_law_index}: - - -\\n\\n')\n",
        "    print(laws.loc[original_law_index, 'texto'])\n",
        "    print(f'\\n\\n- - - LEI COMPARADA: {compared_law_index} - - -\\n\\n')\n",
        "    print(laws.loc[compared_law_index, 'texto'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_sim_overall = np.max(tf_similarities)\n",
        "print(f'Maior similaridade entre duas Leis: {max_sim_overall}')\n",
        "\n",
        "original_law_index = np.argmax(tf_similarities)\n",
        "most_similar_law_index = most_similar_indexes_tf[original_law_index]\n",
        "\n",
        "print_laws(original_law_index, most_similar_law_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JBmGOe10T_3",
        "colab_type": "text"
      },
      "source": [
        "As leis 5949 e 6026 são idênticas.\n",
        "Opa! Lei 13 e Lei 118 são a mesma lei, com 3 dias de diferença. Por que existe isso?"
      ]
    },
    {
      "source": [
        "### TF-IDF\n",
        "\n",
        "Outra representação possível para os textos é TF-IDF. \n",
        "Ainda contamos a frequência de cada termo (TF), \n",
        "porém ponderamos esta frequência pela raridade da palavra, \n",
        "medida pela frequência inversa que ela aparece nos documentos\n",
        "(Inverse Document Frequency). \n",
        "Ou seja, quanto mais rara é a palavra no corpus, \n",
        "mais ela caracteriza o texto em que ela aparece, maior será o peso dela."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "NzYMpD_P0T_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43a460b6-2869-4f73-92ae-402bde4416e1"
      },
      "source": [
        "transformer = TfidfTransformer()\n",
        "tfidf_representation = transformer.fit_transform(tf_representation)\n",
        "\n",
        "cos_sim_tfidf = cosine_similarity(tfidf_representation, dense_output=True)\n",
        "cos_sim_tfidf_sorted_idxs = np.argsort(cos_sim_tfidf)\n",
        "\n",
        "tfidf_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Nh12GLZi0T_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b916cfb-fdfc-43ca-d017-4dec67d56fe2"
      },
      "source": [
        "most_similar_law_idx = cos_sim_tfidf_sorted_idxs[original_law_index, -2]\n",
        "tfidf_similarity = cos_sim_tfidf[original_law_index, most_similar_law_idx]\n",
        "\n",
        "print(f'Dada a mesma lei anterior, similaridade com TF-IDF é: {tfidf_similarity}')\n",
        "print_laws(original_law_index, most_similar_law_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Mostram a mesma lei. O que faz sentido, já que as leis são idênticas."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "L_ofWndW0UAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "422a20d3-4355-476e-8ded-5594ed8cca23"
      },
      "source": [
        "most_similar_indexes_tfidf = cos_sim_tfidf_sorted_idxs[:,-2]\n",
        "\n",
        "same_result = (most_similar_indexes_tf == most_similar_indexes_tfidf)\n",
        "print(same_result)\n",
        "print(f\"Concordam em {sum(same_result) / len(same_result) * 100}% dos resultados\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "A lei mais semelhante de acordo com TF e TF-IDF é a mesma 40% das vezes.\n",
        "\n",
        "Vamos dar uma olhada em algumas leis onde os resultados diferem,\n",
        "para ter uma intuição sobre qual representação é melhor para as leis.\n",
        "\n",
        "Vamo sortear indices aleatorios desse vetor e \n",
        "ler as leis que eles representam e as similaridades"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Z2x3NEDM0UAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b263fba8-0fab-4523-dd04-9e36dd189f2e"
      },
      "source": [
        "different_result_indexes = [i for i, _ in enumerate(same_result) if not same_result[i]]\n",
        "comparisons_count = 10\n",
        "drafted_indexes = np.random.randint(0, high=len(different_result_indexes)-1, size=comparisons_count)\n",
        "drafted_laws = [different_result_indexes[i] for i in drafted_indexes]\n",
        "print(drafted_laws)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "eNvPyncl0UAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d91fe26-62de-411d-9cc2-90f3282cb51c"
      },
      "source": [
        "for i in drafted_laws:\n",
        "    print(f'\\n\\nCOMPARACAO UTILIZANDO TF:\\n\\n')\n",
        "    print_laws(i, most_similar_indexes_tf[i])\n",
        "    print('\\n\\nCOMPARACAO UTILIZANDO TF-IDF:\\n\\n')\n",
        "    print_laws(i, most_similar_indexes_tfidf[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4MMxx8J0UAl",
        "colab_type": "text"
      },
      "source": [
        "Como é um sorteio, \n",
        "cada vez que você rodar esse notebook vai ter resultados diferentes.\n",
        "Fique a vontade pra fazer um PR com a comparação de leis diferentes.\n",
        "Abaixo estão comparações da primeira vez que rodei\n",
        "\n",
        "### Lei 1018\n",
        "Lei 1018 é sobre proibição de homenagens a condenados por corrupção.\n",
        "\n",
        "TF trouxe uma lei sobre tornar uma associação pública.\n",
        "\n",
        "TF-IDF trouxe uma lei sobre evento de comemoração de adoção animal.\n",
        "\n",
        "Todas duas erraram.\n",
        "\n",
        "### Lei 5776\n",
        "Lei 5776 sobre pagamento servidor público.\n",
        "\n",
        "TF trouxe: leitura da bíblia na abertura da câmara \n",
        "(que bizarro, diga-se de passagem).\n",
        "\n",
        "TF-IDF: aposentadoria diretor valor vencimento etc.\n",
        "\n",
        "Ambas as leis parecem ter sido trazidas como semelhantes\n",
        "por causa dos nomes próprios contidos nas leis.\n",
        "\n",
        "### Lei 2789\n",
        "Lei 2789 (mil anos da revolução francesa) sobre obrigatoriedade \n",
        "de um servidor formado em primeiros socorros em escolas. \n",
        "\n",
        "TF: faço saber inkaba instituto de karate. \n",
        "\n",
        "TF-IDF: faço saber associação estrela jaco. \n",
        "\n",
        "Novamente as semelhanças são os nomes próprios nas leis.\n",
        "\n",
        "### Lei 1772\n",
        "Lei 1772: faço saber sindicato trabalhadores rurais.\n",
        "\n",
        "TF: faço saber associação profissionais sexo.\n",
        "\n",
        "TF-IDF: faço saber associação pequenos agricultures apaeb -\n",
        "a rua da sede é a mesma da lei comparada. \n",
        "\n",
        "TF-IDF se saiu melhor nessa.\n",
        "Os nomes das pessoas em TF eram os mesmos da Lei,\n",
        "mas em TF-IDF não.\n",
        "O fator decisivo aqui foi o nome da rua, que era o mesmo.\n",
        "Ponto pra TF-IDF.\n",
        "\n",
        "### Lei 530\n",
        "Lei 530: faço saber igreja ministerio pentecostal fogo gloria.\n",
        "rua volta redonda bairro campo limpo.\n",
        "\n",
        "TF: faço saber instituto nobre sede rodovia br km cis.\n",
        "nomes das pessoas iguais.\n",
        "\n",
        "TF-IDF: faço saber igreja evangelica pentecostal monte carmelo\n",
        "rua espassonavel bairro george americo.\n",
        "prefeitos diferentes.\n",
        "\n",
        "### Lei 4810\n",
        "Lei: comenda.\n",
        "nomes: godofredo rebell figueiredo filho,\n",
        "raymundo luiz oliveira lopes.\n",
        "\n",
        "TF: comenda.\n",
        "nomes: godofredo rebello figueiredo filho,\n",
        "nilton bellas vieira.\n",
        "\n",
        "TF-IDF: comenda.\n",
        "nomes: godofredo rebello figueiredo filho,\n",
        "raimundo antonio carneiro pinto.\n",
        "\n",
        "As duas acertaram\n",
        "\n",
        "### Lei 5238 \n",
        "Lei 5238: promulgação de novas vias públicas.\n",
        "A via por TF-IDF passa por mais ruas iguais.\n",
        "\n",
        "### Lei 5383\n",
        "Lei promulga academia de ginástica.\n",
        "TF: promulga empresas serviço funerario.\n",
        "TF-IDF: promulga novos aparelhos de ginástica.\n",
        "\n",
        "### Outras\n",
        "As outras leis eram: \"_visualizar legislativo ba_\".\n",
        "Ambas trouxeram textos idênticos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwB0E6_80UAm",
        "colab_type": "text"
      },
      "source": [
        "Ok! Massa! Funciona!\n",
        "\n",
        "Pelos resultados acima, TF-IDF se saiu melhor. \n",
        "Inclusive pra retornar semelhança \n",
        "por nomes de ruas e de bairros,\n",
        "que é o que a gente quer pras buscas.\n",
        "\n",
        "Mesmo com 28k features,\n",
        "o resultado foi bastante rápido. \n",
        "Caso tivessemos um corpus maior,\n",
        "poderíamos ainda usar PCA pra reduzir as dimensões\n",
        "e ainda assim calcular a similaridade\n",
        "mantendo as relações entre os documentos."
      ]
    },
    {
      "source": [
        "### Vetor de palavras - word embedding\n",
        "\n",
        "***AVISO! ESTA PARTE GASTA MUITA MEMÓRIA!***\n",
        "\n",
        "A ideia dessa representação é \n",
        "criar um vetor pra cada palavra,\n",
        "com base nas palavras vizinhas.\n",
        "\n",
        "Isto vem da hipótese linguística distribucional:\n",
        "uma palavra é parecida com outra se\n",
        "suas vizinhas são as mesmas.\n",
        "\n",
        "Ou ainda:\n",
        "\"conhecerás a palavra pelas compainhas que ela mantém\".\n",
        "\n",
        "Na prática,\n",
        "vamos utilizar um método bem simples\n",
        "baseado nesta hipótese.\n",
        "Cada palavra é representada por um vetor\n",
        "de _n_ dimensões,\n",
        "onde _n_ é o tamanho do vocabulário.\n",
        "Os valores de cada dimensão são \n",
        "a frequência com que a palavra \n",
        "representada por esta dimensão \n",
        "aparece como vizinha da palavra sendo representada.\n",
        "\n",
        "A vizinhança pode variar.\n",
        "Neste caso,\n",
        "temos como vizinhas palavras até 2 tokens de distância. \n",
        "Portanto,\n",
        "na frase \"dados abertos de feira é massa\",\n",
        "a palavra \"_de_\" é vizinha de todas as palavras,\n",
        "exceto \"_massa_\"."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-e541cf87d6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mseguir\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mseguir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.pyenv/versions/dafsa-analises/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.pyenv/versions/dafsa-analises/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "seguir = input(\"O trecho a seguir consome muita memoria.\\\n",
        "    (em torno de 12 GB). Deseja prosseguir? (s/n)\")\n",
        "if seguir == \"n\":\n",
        "    while True:\n",
        "        seguir = input()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "wS-15fVG0UAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "53ce1ce4-ac2c-40fd-afae-d1b2dd1c7203"
      },
      "source": [
        "cleaned_text = ' '.join(laws['texto_limpo'].tolist())\n",
        "cleaned_text = cleaned_text.split()\n",
        "unique_words = set(cleaned_text)\n",
        "print(f\"Text length: {len(cleaned_text)}\")\n",
        "print(f\"Vocabulary length: {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTXaa1WD0UAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_indexes = {}\n",
        "for i, word in enumerate(unique_words):\n",
        "    word_indexes[word] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIXTyXpb0UAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c6ea58f9-5618-47be-e21f-9b4a08279546"
      },
      "source": [
        "# Esta parte consome muita memória\n",
        "# pra rodar esta parte, descomente a linha abaixo\n",
        "word_embedding_matrix = np.zeros(\n",
        "    (len(unique_words), len(unique_words)), \n",
        "    dtype=np.int16)\n",
        "word_embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDi3dF-0UAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d01c813c-0421-44ad-d3e4-da2b0ed6be7d"
      },
      "source": [
        "neighborhood = 2\n",
        "for idx, word in enumerate(cleaned_text):\n",
        "    for i in range(1, neighborhood):\n",
        "        neighbor_word = cleaned_text[idx+i]\n",
        "\n",
        "        word_idx = word_indexes[word]\n",
        "        neighbor_index = word_indexes[neighbor_word]\n",
        "\n",
        "        word_embedding_matrix[word_idx, neighbor_index] += 1\n",
        "        word_embedding_matrix[neighbor_index, word_idx] += 1\n",
        "    if (idx == len(cleaned_text) - neighborhood):\n",
        "        break\n",
        "word_embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Oyjsnw0UA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "174fbe2d-9bcf-421c-c4f9-29091f5bf968"
      },
      "source": [
        "# Transform to sparse, to avoid memory consumption\n",
        "from scipy.sparse import csr_matrix\n",
        "word_embedding_matrix = csr_matrix(word_embedding_matrix)\n",
        "word_embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arG4D1Vv0UA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2fc4f7fd-c656-4522-a092-6067909f7dd2"
      },
      "source": [
        "# We have our word representation\n",
        "# Lets test it checking the most similar words to 10 random words\n",
        "words_cosine_similarity_matrix = cosine_similarity(word_embedding_matrix, dense_output=False)\n",
        "words_cosine_similarity_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "6XKVcQWK0UA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47a9d847-1c59-4256-8cf2-8a722f8aea99"
      },
      "source": [
        "palavras_semelhantes = np.argsort(words_cosine_similarity_matrix[0].toarray())\n",
        "len(palavras_semelhantes[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "cX8aNaJt0UBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03f6f0b3-3df3-4db6-cad9-d55a30b4bda2"
      },
      "source": [
        "drafted_words_index = np.random.randint(len(unique_words), size=10)\n",
        "\n",
        "def show_words(idx: int, similar_words: list, vocabulary: list):\n",
        "    word = vocabulary[idx]\n",
        "    print(f'Lista de palavras similares a {word} - {idx}:')\n",
        "    for i in similar_words:\n",
        "        word = vocabulary[i]\n",
        "        print(f'{word} - {i}')\n",
        "    print('\\n- - - - - \\n\\n')\n",
        "\n",
        "vocabulary = list(word_indexes.keys())\n",
        "for idx in drafted_words_index:\n",
        "    sorted_cosine_similarities_array = np.argsort(words_cosine_similarity_matrix[idx].toarray())\n",
        "    similar_words = sorted_cosine_similarities_array[0][-10:-1]\n",
        "    show_words(idx, similar_words, vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaHPf6bo0UBG",
        "colab_type": "text"
      },
      "source": [
        "Neste corpus, pra algumas palavras,\n",
        "a hipótese distribucional parece funcionar bem,\n",
        "pra outras nem tanto, pra outras não funciona.\n",
        "\n",
        "Semelhantes a \"outorgar\" temos:\n",
        "\"permutar\", \"editar\", \"contratar\", \"doar\",\n",
        "\"conceder\", \"dispensar\", \"celebrar\", \"subscrever\", \"proibir\".\n",
        "Embora a semântica (significado) não seja necessariamente próxima,\n",
        "todas as palavras são verbos, então a sintaxe é próxima.\n",
        "\n",
        "Semelhantes a \"ibitita\":\n",
        "\"axixa\", \"ibirarema\", \"peritoro\", \"piracaia\", \"igarata\",\n",
        "\"erechim\", \"itaperuna\", \"piata\", \"vandinha\".\n",
        "Todos parecem nomes de locais.\n",
        "\n",
        "Existem casos horríveis.\n",
        "Semelhantes à \"coesao\" temos:\n",
        "\"sedeso\", \"his\", \"ctps\", \"zeis\", \"pnas\", \"cgfmhis\", \"snhis\", \"acemas\".\n",
        "O que significam essas palavras?\n",
        "Talvez seja útil melhorar a qualidade do pré-processamento pra melhorar na indexação.\n",
        "\n",
        "Semelhantes à \"separando\" temos: \"agrossilvopastoris\", \"cemiteriais\", \"solidos\",\n",
        "\"molhados\", \"domiciliares\", \"volumosos\", \"baldios\", \"antecedencia\", \"dimensao\".\n",
        "\n",
        "Há casos mistos.\n",
        "Semelhantes `a \"trasporte\" (note o erro) temos:\n",
        "\"meia\" (talvez meia passagem?), \"transporte\" (a palavra correta aparece em segundo),\n",
        "\"roletas\", \"vala\" (?), \"trafegos\", \"convencional\" (?),\n",
        "\"edificar\" (?), \"passageiros\", \"fretado\".\n",
        "\n",
        "Talvez o corpus seja pequeno demais \n",
        "pra encontrar as relações entre as palavras só contando?\n",
        "Há de se testar se não é melhor então trabalhar com vetores de palavras,\n",
        "mesmo aprendidos em um corpus pequeno.\n",
        "Segundo o paper\n",
        "\"Don't count, predict! a systematic comparison of context-counting vs.\n",
        "context-predicting semantic vectors (2014) - Baroni, Dinu, Kruszeweski\",\n",
        "predizer é melhor que contar.\n",
        "Há de se testar se neste nosso contexto isso também se verifica.\n",
        "\n",
        "Por hora,\n",
        "vamos testar se a busca melhora ou não utilizando as palavras.\n",
        "Então vamos construir a representação das leis.\n",
        "\n",
        "# Construindo representação das leis com base na hipotese distribucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7VoHo8x06hr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "FLTahner0UBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "97f30ae5-a27a-4fa9-b364-204bd621b71d"
      },
      "source": [
        "# Cada lei vai ser a soma dos word_embedding_matrix de suas palavras\n",
        "# Usando np.zeros gasta muita memoria, mas csr_matrix eh muito lento\n",
        "word_embedding_representation = np.zeros((len(laws['texto_limpo']), word_embedding_matrix.shape[1]))\n",
        "for idx, law in enumerate(laws['texto_limpo']):\n",
        "    for word in law.split():\n",
        "        word_index = word_indexes[word]\n",
        "        word_embedding_representation[idx] += word_embedding_matrix[word_index]\n",
        "word_embedding_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU1T1aya26Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_cosine_similarity = cosine_similarity(word_embedding_representation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK2ZpkXI3Dh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_similar_indexes_word_embedding = [idx for idx in np.argsort(word_embedding_cosine_similarity)[:,-2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpgoJqA3u0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bbd5953-0041-482c-99e0-a56eccc8ffc6"
      },
      "source": [
        "# Diferenca de vetores pra TFIDF eh bem maior.\n",
        "# Vamos samplear algumas dessas diferencas e \n",
        "# mostrar uma lei q tanto TFIDF como Count erraram\n",
        "different_result_from_tfidf = (most_similar_indexes_word_embedding != most_similar_indexes_tfidf)\n",
        "print(f\"Porcentagem de resultados diferentes de TFIDF:\\\n",
        "    {sum(different_result_from_tfidf)*100 / len(different_result_from_tfidf)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOwOOGp-4ICI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88b3084f-d0ab-4a29-eb06-a42862fcf15a"
      },
      "source": [
        "drafted_laws_index = np.random.randint(len(different_result_from_tfidf), size=10)\n",
        "for i in drafted_laws_index:\n",
        "    if different_result_from_tfidf[i]:\n",
        "        print(f'\\n\\nVETOR DE PALAVRAS:\\n\\n')\n",
        "        print_laws(i, most_similar_indexes_word_embedding[i])\n",
        "        print('\\n\\nTF-IDF:\\n\\n')\n",
        "        print_laws(i, most_similar_indexes_tfidf[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDqTxHud7z8N",
        "colab_type": "text"
      },
      "source": [
        "Parece que TF-IDF é um pouco melhor na comparação de leis,\n",
        "pq traz resultados mais relevantes quando comparados nome de bairros e ruas.\n",
        "No entanto, a forma vetorizada parece ser boa pra reconhecer formatos da Lei em geral,\n",
        "uma especie de POS, reconhecendo que existe uma entidade alí ou verbo etc.\n",
        "Ao menos foi minha impressão.\n",
        "Cabe mais investigação a respeito.\n",
        "\n",
        "Vale salientar que a qualidade dos vetores parece não estar tão boa.\n",
        "Vide a semelhança de palavras. Como fazer pra consertar isso?\n",
        "Seria muito interessante corrigir isso pra ver as palavras mais semelhantes à\n",
        "educação,saúde etc e também pra visualizar com tsne os clusters gerados a partir daí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipPoW9DQ0UAn",
        "colab_type": "text"
      },
      "source": [
        "## Outras opções\n",
        "### Indexar\n",
        "\n",
        "Há outras formas de indexar os documentos e de recuperar, também simples.\n",
        "Uma outra forma de indexar, por exemplo,\n",
        "é fazer um vetor pra cada palavra contando as palavras vizinhas.\n",
        "E depois, o vetor do documento seria a soma dos vetores das palavras.\n",
        "É uma forma interessante porque pode gerar visualizações interessantes\n",
        "entre a similaridade das palavras.\n",
        "Por exemplo, no corpus das Leis Municipais,\n",
        "a quais palavras EDUCAÇÃO mais se assemelha? Ou SAÚDE? Etc.\n",
        "\n",
        "Outra forma é contar n-gramas - por exemplo, bi-gramas:\n",
        "duas palavras juntas formando um token.\n",
        "Dessa forma, você possui uma matriz maior\n",
        "e de certa forma uma relação entre a sequencialidade das palavras,\n",
        "que pode ser útil pra nomes de pessoas e bairros, como citado acima.\n",
        "\n",
        "### Recuperar\n",
        "\n",
        "Outra forma de recuperar é por local sensitive hashing.\n",
        "Divide em vários planos múltiplas vezes\n",
        "e retorna os resultados que estão na mesma região da query.\n",
        "No entanto, o corpus não é grande o suficiente pra precisar essa estratégia,\n",
        "que é mais pra grandes corpora.\n",
        "O método acima (calcular a simlaridade cosseno e retornar os maiores valores)\n",
        "é rápido o suficiente pra parecer instantâneo.\n",
        "Talvez com uma demanda mais alta pelo servidor venha a necessidade de aumentar\n",
        "a velocidade da busca, porém por enquanto não é o caso.\n",
        "Mais sobre recuperação: Google lançou [novo método]\n",
        "(https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html)\n",
        "e uma lib pra isso agora, dia 28 de Julho.\n",
        "\n",
        "### Avaliação\n",
        "\n",
        "Com múltiplas formas de indexar e recuperar vem o dilema:\n",
        "como avaliar se uma é melhor que a outra?\n",
        "Repetir o processo acima pra todas as opções?\n",
        "Isto é, mostrar N melhores resultados e comparar manualmente?\n",
        "Ou colocar labels em algumas leis? Ex: essa lei trata disso, com tais entidades.\n",
        "Checar formas de avaliação.\n",
        "Se tivesse em produção, podia avaliar por CTR por ex, mas não é o caso"
      ]
    }
  ]
}
