{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória de textos\n",
    "\n",
    "Sobre o que falam os documentos oficiais? \n",
    "Quais as palavras mais frequentes?\n",
    "Este é um notebook para \n",
    "exploração inicial do texto dos documentos municipais.\n",
    "Atualmente só mostra as palavras mais frequentes,\n",
    "mas há outras análises interessantes.\n",
    "\n",
    "O exemplo é com as Leis Municipais,\n",
    "porém qualquer documento oficial pode ser carregado\n",
    "para realizar a mesma análise.\n",
    "\n",
    "### Algumas ideias para melhorar esse notebook:\n",
    "\n",
    "- Separar os documentos por tópicos,\n",
    "usando Latent Semantic Analysis (LSA) ou LDA, por exemplo,\n",
    "e calcular a frequência de palavras pra cada tópico\n",
    "- Separar entidades (nome de pessoas, ruas) das outras palavras\n",
    "- Rodar o Part of Speech Tagging (POS Tagging) do Spacy\n",
    "e calcular frequências para cada categoria\n",
    "(substantivo, adjetivo, etc)\n",
    "\n",
    "### Algumas referências para ideias e melhorias:\n",
    "\n",
    "- [Como criar nuvem de palavras](https://medium.com/turing-talks/introdu%C3%A7%C3%A3o-ao-processamento-de-linguagem-natural-com-baco-exu-do-blues-17cbb7404258)\n",
    "- [Explore 175 Years of Words in Scientific American](https://www.scientificamerican.com/article/explore-175-years-of-words-in-scientific-american/)\n",
    "e\n",
    "[How to Turn 175 Years of Words in Scientific American into an Image](https://www.scientificamerican.com/article/how-to-turn-175-years-of-words-in-scientific-american-into-an-image/)\n",
    "- [Tutorial de visualização de informações textuais](https://infovis.fh-potsdam.de/tutorials/infovis5text.html)\n",
    "- [Tutorial de análise exploratória de texto](https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a)\n",
    "- [Análise dos tweets do congresso americano](https://congress.pudding.cool/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-requisitos\n",
    "\n",
    "Para rodar este notebook,\n",
    "você precisa de um conjunto de textos (corpus).\n",
    "\n",
    "Atualmente usamos o corpus das Leis Municipais,\n",
    "presente no arquivo `leis.json`,\n",
    "disponível [no Kaggle](https://www.kaggle.com/anapaulagomes/leis-do-municpio-de-feira-de-santana/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_laws = pd.read_json('leis.json')\n",
    "city_laws.drop(['documento'], inplace=True, axis=1)\n",
    "city_laws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_laws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abaixo um exemplo de uma lei do munícipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(city_laws.iloc[len(city_laws)-1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quais as palavras mais comuns?\n",
    "\n",
    "A seguir, geramos uma visualização\n",
    "das palavras mais comuns no texto das Leis.\n",
    "Algo que pode ser desenvolvido em uma núvem de palavras.\n",
    "\n",
    "A ideia é descobrir palavras chave recorrente nas Leis.\n",
    "Sobre o que falam nossas Leis Municiapis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(f\"Esperava string, recebido {type(text)}\")\n",
    "\n",
    "    # Remove pontuação, dígitos e espaços em branco\n",
    "    text = re.findall(r\"[A-Za-zÀ-ú]+[-A-Za-zÀ-ú]*\", text.lower())\n",
    "\n",
    "    # Remove stopwords\n",
    "    return [word for word in text if word not in stopwords.words(\"portuguese\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = ' '.join(city_laws['texto'].tolist())\n",
    "text = clean_text(text)\n",
    "\n",
    "unique_words_count = len(set(text))\n",
    "print(f'Número de palavras únicas no texto: {unique_words_count}')"
   ]
  },
  {
   "source": [
    "## Removendo stopwords\n",
    "\n",
    "Stopwords são palavras a serem removidas na etapa de\n",
    "pré-processamento do texto. Em geral são palavras muito\n",
    "comuns, utilizadas em quase todos os textos,\n",
    "ou não possuem valor descritivo do que diz o texto.\n",
    "\n",
    "Em ambos os casos, não possuem informação sobre o que trata\n",
    "o texto, que é o que a gente quer visualizar com a\n",
    "frequencia das palavras do texto.\n",
    "\n",
    "O método `clean_text` já remove algumas stopwords\n",
    "padrões do português, como preposições, artigos, etc:\n",
    "(\"de\", \"a\", \"este\").\n",
    "\n",
    "Utilizamos o módulo Counter do Python para visualizar \n",
    "as palavras mais comuns nos textos das Leis\n",
    "e decidir se elas possuem valor semântico ou não. \n",
    "Isto é, se descrevem o conteúdo do texto ou não.\n",
    "As palavras que não possuirem,\n",
    "incluímos na lista de stopwords, palavras a serem \n",
    "removidas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "counter_ = Counter(text)\n",
    "counter_.most_common(100)"
   ]
  },
  {
   "source": [
    "### Selecionando as stopwords\n",
    "\n",
    "Palavras como:\n",
    "'art' (artigo),\n",
    "'municipal',\n",
    "'lei',\n",
    "'rua',\n",
    "'feira',\n",
    "'santana',\n",
    "'prefeito',\n",
    "'câmara',\n",
    "'município',\n",
    "'publicação',\n",
    "'seguinte',\n",
    "'disposições',\n",
    "'estado',\n",
    "'bahia',\n",
    "'vigor',\n",
    "aparecem em quase todas as Leis, portanto\n",
    "elas não identificam bem o texto das Leis.\n",
    "\n",
    "Letras do alfabeto e números romanos, como:\n",
    "'i', 'ii', 'iii',\n",
    "'d', 'n', 'r'\n",
    "também aparecem bastante no texto das Leis\n",
    "e não possuem valor semântico. Também vamos\n",
    "remove-las.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    custom_stopwords = ['feira', 'santana', 'art', 'municipal', 'lei', 'r', \n",
    "    'prefeito', 'câmara', 'município', 'data', 'seguinte', 'disposições',\n",
    "    'estado', 'bahia', 'vigor', 'secretário', 'decreto', 'projeto', \n",
    "    'iii', 'i', 'ii',  'contrário', 'presidente', 'artigo', 'rua',\n",
    "    'faço', 'parágrafo', 'executivo', 'gabinete', 'único', 'sanciono', \n",
    "    'desta', 'v', 'iv', 'autoria', 'através', 'deste', 'vice', 'autor',\n",
    "    'qualquer', 'b', 'sobre', 'das', 'decorrentes', 'fica', 'dias',\n",
    "    'resolução', 'geral', 'uso', 'ato', 'diretiva', 'exercício',\n",
    "    'seguintes', 'meio', 'm', 'c', 'd', 'n', 'correrão', 'publicação']\n",
    "    \n",
    "    return [word for word in text if word not in custom_stopwords]\n",
    "\n",
    "text = remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "fd = FreqDist(text)\n",
    "fd.plot(30, title='Palavras x Frequência', cumulative=False)"
   ]
  },
  {
   "source": [
    "## Analisando o resultado\n",
    "\n",
    "O que esperava era obter palavras comuns no\n",
    "texto das Leis que também descrevessem o conteúdo.\n",
    "\n",
    "Existem algumas palavras descritivas do conteúdo,\n",
    "por exemplo \"revogadas\", \"secretaria\", \"serviços\",\n",
    "\"despesas\", \"social\", \"saúde\",\n",
    "de certa forma descrevem o conteúdo das Leis.\n",
    "\n",
    "Aparecem alguns nomes próprios, como \"José\",\n",
    "\"Silva\", \"Santos\", \"Carvalho\". Nomes frequentes\n",
    "na base de dados. Os nomes do prefeito em exercício,\n",
    "do edil, presidente da câmara e outros cargos,\n",
    "frequentemente aparecem no texto das Leis.\n",
    "O que por exemplo explica os nomes José e Carvalho,\n",
    "que aparecem no nome do prefeito José Ronaldo de Carvalho,\n",
    "ganhador de 4 pleitos no município.\n",
    "\n",
    "No entanto apenas estas palavras não dão uma boa\n",
    "indicação sobre o conteúdo destas Leis. Por isso,\n",
    "sugerimos no começo deste notebook algumas técnicas\n",
    "para extração tópicos dos textos, bem como as \n",
    "palavras mais frequentes nestes tópicos.\n",
    "Possivelmente este procedimento retornará um \n",
    "resultado mais interpretável.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
