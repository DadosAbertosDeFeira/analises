{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória de textos\n",
    "\n",
    "Sobre o que falam os documentos oficiais? \n",
    "Quais as palavras mais frequentes?\n",
    "Este é um notebook para \n",
    "exploração inicial do texto dos documentos municipais.\n",
    "Atualmente só mostra as palavras mais frequentes,\n",
    "mas há outras análises interessantes.\n",
    "\n",
    "O exemplo é com as Leis Municipais,\n",
    "porém qualquer documento oficial pode ser carregado\n",
    "para realizar a mesma análise.\n",
    "\n",
    "### Algumas ideias para melhorar esse notebook:\n",
    "\n",
    "- Separar os documentos por tópicos,\n",
    "usando Latent Semantic Analysis (LSA) ou LDA, por exemplo,\n",
    "e calcular a frequência de palavras pra cada tópico\n",
    "- Separar entidades (nome de pessoas, ruas) das outras palavras\n",
    "- Rodar o Part of Speech Tagging (POS Tagging) do Spacy\n",
    "e calcular frequências para cada categoria\n",
    "(substantivo, adjetivo, etc)\n",
    "\n",
    "### Algumas referências para ideias e melhorias:\n",
    "\n",
    "- [Como criar nuvem de palavras](https://medium.com/turing-talks/introdu%C3%A7%C3%A3o-ao-processamento-de-linguagem-natural-com-baco-exu-do-blues-17cbb7404258)\n",
    "- [Explore 175 Years of Words in Scientific American](https://www.scientificamerican.com/article/explore-175-years-of-words-in-scientific-american/)\n",
    "e\n",
    "[How to Turn 175 Years of Words in Scientific American into an Image](https://www.scientificamerican.com/article/how-to-turn-175-years-of-words-in-scientific-american-into-an-image/)\n",
    "- [Tutorial de visualização de informações textuais](https://infovis.fh-potsdam.de/tutorials/infovis5text.html)\n",
    "- [Tutorial de análise exploratória de texto](https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a)\n",
    "- [Análise dos tweets do congresso americano](https://congress.pudding.cool/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-requisitos\n",
    "\n",
    "Para rodar este notebook,\n",
    "você precisa de um conjunto de textos (corpus).\n",
    "\n",
    "Atualmente usamos o corpus das Leis Municipais,\n",
    "presente no arquivo `leis.json`,\n",
    "disponível [no Kaggle](https://www.kaggle.com/anapaulagomes/leis-do-municpio-de-feira-de-santana/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_laws = pd.read_json('leis.json')\n",
    "city_laws.drop(['documento'], inplace=True, axis=1)\n",
    "city_laws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_laws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abaixo um exemplo de uma lei do munícipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(city_laws.iloc[len(city_laws)-1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quais as palavras mais comuns?\n",
    "\n",
    "A seguir, geramos uma visualização\n",
    "das palavras mais comuns no texto das Leis.\n",
    "Algo que pode ser desenvolvido em uma núvem de palavras.\n",
    "\n",
    "A ideia é descobrir palavras chave recorrente nas Leis.\n",
    "Sobre o que falam nossas Leis Municiapis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text, str):\n",
    "    nfkd_form = unicodedata.normalize(\"NFKD\", text)\n",
    "    return \"\".join([char for char in nfkd_form if not unicodedata.combining(char)])\n",
    "\n",
    "def clean_text(text, rm_accents=False):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(f\"Esperava string, recebido {type(text)}\")\n",
    "\n",
    "    # Remove pontuação, dígitos e espaços em branco\n",
    "    text = \" \".join(re.findall(r\"[A-Za-zÀ-ú]+[-A-Za-zÀ-ú]*\", text.lower()))\n",
    "\n",
    "    if rm_accents:\n",
    "        text = remove_accents(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    # Essas palavras abaixo são muito comuns nos textos das leis\n",
    "    # (aparecem em quase todos os textos)\n",
    "    # ou não possuem valor descritivo do que diz o texto. \n",
    "    # Em ambos os casos, não possuem informação sobre o que trata\n",
    "    # o texto, que é o que a gente quer visualizar com a \n",
    "    # frequencia das palavras do texto.\n",
    "    nltk_stopwords = stopwords.words(\"portuguese\")\n",
    "    custom_stopwords = ['feira', 'santana', 'art', 'municipal', 'lei', 'r', \n",
    "    'prefeito', 'câmara', 'municipio', 'data', 'seguinte', 'disposições',\n",
    "    'estado', 'bahia', 'vigor', 'secretário', 'decreto', 'projeto', \n",
    "    'iii', 'i', 'ii',  'contrário', 'presidente', 'artigo',\n",
    "    'faço', 'parágrafo', 'executivo', 'gabinete', 'único', 'sanciono', \n",
    "    'desta', 'v', 'iv', 'autoria', 'através', 'deste', 'vice', 'autor',\n",
    "    'qualquer', 'b', 'decretou', 'execução', 'sobre', 'das', 'decorrentes',\n",
    "    'decreta', 'resolução', 'geral', 'uso', 'ato', 'diretiva', 'exercício',\n",
    "    'seguintes', 'meio', 'm', 'c', 'd', 'n', 'correrão']\n",
    "    all_stopwords = nltk_stopwords + custom_stopwords\n",
    "\n",
    "    return [word for word in text.split() if word not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = ' '.join(city_laws['texto'].tolist())\n",
    "text = clean_text(text)\n",
    "\n",
    "unique_words_count = len(set(text))\n",
    "print(f'Número de palavras únicas no texto: {unique_words_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "fd = FreqDist(text)\n",
    "fd.plot(30, title='Palavras x Frequência', figsize=(20,10), cumulative=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
